
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    [{"authors":null,"categories":null,"content":"My name is Zixing Lei(雷梓行) and you can just call me Elwood. Currently I am a master student in the Cooperative Medianet Innovation Center(CMIC) of Shanghai Jiao Tong University(SJTU), supervised by Prof. Siheng Chen. My research interests include computer vision, embodied AI and multi-robots perception.\n","date":1706486400,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1706486400,"objectID":"31469598642a80531c1159a83877f4dc","permalink":"","publishdate":"0001-01-01T00:00:00Z","relpermalink":"","section":"authors","summary":"My name is Zixing Lei(雷梓行) and you can just call me Elwood. Currently I am a master student in the Cooperative Medianet Innovation Center(CMIC) of Shanghai Jiao Tong University(SJTU), supervised by Prof.","tags":null,"title":"Zixing Lei","type":"authors"},{"authors":["Zixing Lei","Zhenyang Ni","Ruize Han","Shuo Tang","Chen Feng","Siheng Chen","Yanfeng Wang"],"categories":null,"content":"","date":1706486400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1706486400,"objectID":"e91210050c79879cbeaa03ebc59599d8","permalink":"https://example.com/publication/conference-paper/freealign/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/conference-paper/freealign/","section":"publication","summary":"We propose a novel INterruption-aware robust COoperative Perception (V2X-INCOP) solution for V2X communication-aided autonomous driving, which leverages historical information to recover missing information due to interruption.","tags":["Source Themes"],"title":"[ICRA 2024] Robust Collaborative Perception without External Localization and Clock Devices","type":"publication"},{"authors":["Zixing Lei","Yiming Zhang","Yuxin Xiong","Siheng Chen"],"categories":null,"content":" ","date":1696896000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1696896000,"objectID":"87f44b01ca9fcc72e5e863a33ad18588","permalink":"https://example.com/publication/conference-paper/ecisqa/","publishdate":"2023-10-10T00:00:00Z","relpermalink":"/publication/conference-paper/ecisqa/","section":"publication","summary":"In the proposed interactive sketch question answering (ISQA) task, two collaborative players are interacting to answer a question about an image. This task emphasizes multi-round interaction, which is essential in daily human communication.","tags":[],"title":"[NeurIPS2023] Emergent Communication in Interactive Sketch Question Answering","type":"publication"},{"authors":["Zixing Lei"],"categories":null,"content":" ","date":1695117600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1695117600,"objectID":"a6c2316782ff2864b2fba6180b14754d","permalink":"https://example.com/talk/invited-talk-at-renmin-university-of-china/","publishdate":"2023-09-20T00:00:00Z","relpermalink":"/talk/invited-talk-at-renmin-university-of-china/","section":"event","summary":"Robust collboartive perception, 2022-2023.","tags":[],"title":"Invited talk at Renmin University of China","type":"event"},{"authors":["Runli Ren","Zixing Lei","Zi Wang","Dianati Mehrdad","Yafei Wang","Siheng Chen","Wenjun Zhang"],"categories":null,"content":" ","date":1688688000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1688688000,"objectID":"138cf3b83b4a7271ef34c88eb84acda1","permalink":"https://example.com/publication/preprint/incop/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/preprint/incop/","section":"publication","summary":"We propose a novel INterruption-aware robust COoperative Perception (V2X-INCOP) solution for V2X communication-aided autonomous driving, which leverages historical information to recover missing information due to interruption.","tags":["Source Themes"],"title":"Interruption-Aware Cooperative Perception for V2X Communication-Aided Autonomous Driving","type":"publication"},{"authors":["Yue Hu","Shaoheng Fang","Zixing Lei","Yiqi Zhong","Siheng Chen"],"categories":null,"content":" ","date":1664496000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1664496000,"objectID":"78ebdc75f6388eca3f7919a9f94bce89","permalink":"https://example.com/publication/conference-paper/where2comm/","publishdate":"2022-09-10T00:00:00Z","relpermalink":"/publication/conference-paper/where2comm/","section":"publication","summary":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.","tags":[],"title":"[NeurIPS2022] Where2comm: Communication-Efficient Collaborative Perception via Spatial Confidence Maps","type":"publication"},{"authors":null,"categories":null,"content":"图小波神经网络 论文信息 Paper: [ICLR 2019] Graph wavelet neural network[1]Link: https://arxiv.org/pdf/1904.07785.pdf 背景梳理 作者认为，对于已经在方方面大获成功的卷积神经网络CNNs而言，其包含一个潜在的先觉条件，即数据应是满足欧几里得结构的。对于大量的非欧数据而言，现阶段人们尝试将CNN推广至图数据科学，也即GCN。现阶段有两种主要方法来处理：一是遵循传统CNN做法的空间方法，直接在顶点域上定义卷积操作。对于每个顶点，卷积被定义为位于其邻域内所有顶点的加权平均函数，加权函数表征其邻居对目标顶点施加的影响。二是谱方法通过，图傅立叶变换和卷积定理定义卷积。谱方法利用图傅里叶变换将顶点域中定义的信号转换为谱域，例如图拉普拉斯矩阵的特征向量所跨越的空间，然后在谱域中定义滤波器，保持CNNs的权重共享特性。\n对于谱方法(Spectral GNN)来说，其实际应用当中存在若干问题，可简单概括为以下几点：\n谱方法的建模依赖于图拉普拉斯矩阵的特征值分解，具有很高的计算复杂度谱方法中傅立叶基向量没有稀疏性，也导致了无法加速，计算效率低谱方法中的傅立叶基向量是表示全局性的信号，不够突出其局部化的特征 为解决这些问题，本文提出图小波神经网络(GWNN)，即将谱方法图神经网络中的傅立叶基替换为小波基，作者认为其具有以下好处：\nGWNN和谱方法相比，不需要对拉普拉斯矩阵进行分解，有效降低了计算复杂度图小波基稀疏的图小波反映了以每个节点为中心的信息扩散。 信号处理中的傅立叶与小波 这里我们简单介绍一下在信号处理当中，小波基与傅立叶基的一些恩怨情仇。 为什么在傅立叶变换如此优美、且具有清晰物理含义的频谱分析方法提出后，我们还要发展相对而言更“黑盒”的小波呢？原因可以简单概括为，对于非平稳过程，傅立叶变换具有较大的局限性。 例如下图[2],左侧时域图表示了三个有较大差距的时域信号。对于第一个信号而言，其在整个时域中都具有相同的频谱分量，我们称之为“平稳的”。而后两个信号的频率则会随着时间的变换而发生改变。对三个差距巨大的信号进行快速傅立叶变换后我们发现，其频谱图却非常相似。 这说明傅立叶变换缺乏区分信号平稳性的能力，而现实世界中大量存在的正是非平稳信号，真正的平稳信号通常来自于人类刻意制造的信号发生器。为了解决这个问题，信号处理学家们提出了短时傅立叶变换(STFT，short-time Fourier transform)的概念：即对信号加窗，认为信号在一个很小的窗口内是平稳的，再对其进行傅立叶分析。但这也不是一个完美的解决方案，因为在窗长的选择上存在一个非常艰难的trade-off：如果窗长太长则导致其时间分辨率差，窗长太短则导致其频谱分辨率差。“我们无法同时获取一个信号（粒子）的频率（动量）时刻（位置）”堪称信号处理中的不确定性原理。这其中的巧妙联系也许正暗示了波粒二象性。(德布罗意波、物质波)\n于是，聪明的信号科学家们又想出了新的办法。既然对于在整个时域都存在的傅立叶基来说，需要通过STFT这种操作来使其具有对非平稳信号的区分能力，我们为何不直接设计本身就是有限长的基呢？小波变化的基本思路便是“将无限长的三角函数基换成了有限长的会衰减的小波基。这样不仅能够获取频率信息，也可以知道频域所处的时间。\n好了，这部分就介绍到这里，下面我们继续看GWNN的内容。\n图小波变换 与图傅立叶变换类似，图小波变换将图信号从vertex域映射到spectral域。图小波变换将一组小波设为基：\n其中表示图信号中由节点扩散出的部分，则是一个缩放因子。\n其中是拉普拉斯特征向量组成的矩阵，则是一个缩放矩阵，其中。 图信号的小波变换可写作\n逆变换可写作：\n其中 可以简单地将中的换成来得到。与图傅立叶变换类似，我们可将卷积操作定义为：\n与图傅立叶变换相比，这样定义的图小波变化有什么好处呢？\n1、可以通过快速算法来获得图小波而不需要拉普拉斯矩阵的特征分解，其具体方法请参考[3]2、对于现实世界中的图信号，矩阵和均具有高度的稀疏性：例如在Cora数据集中，中97%的元素均为0。3、每个小波对应于从中心节点扩散的图信号，在顶点域中具有高度的局部化特征。（详见文章附录A）4、图小波变换可以更灵活地调整节点的邻居。可以利用连续的方式，即改变缩放参数s来改变邻域的范围。 图小波神经网络 将傅立叶变换替换为小波变换，GWNN可以视作一个多层的卷积神经网络。其第层的结构为：\n根据该式，每层GWNN的参数复杂度为。其中n是图节点的数量，p是本层的特征通道数，q是下一层的特征通道数。传统的 CNN 方法为每对输入特征和输出特征学习卷积核。 这导致了大量的参数，并且通常需要大量的训练数据来进行参数学习。 这对于基于图的半监督学习是不可接受的。 为了解决这个问题，本文将特征转换与图卷积分离。 GWNN 中的每一层都分为两个组件：特征变换和图卷积。\n实验 作者在半监督节点分类任务上验证了模型的性能，其中包括三个数据集：Cora，Citeseer，Pubmed。与其与方法的比较可由下图所示： 作者也对傅立叶和小波的稀疏性进行了比较，结果如下所示： 可见小波基在稀疏性上具有压倒性的优势。\n参考文献 [1]: Xu, Bingbing, et al. \u0026#34;Graph wavelet neural network.\u0026#34; arXiv preprint arXiv:1904.07785 (2019).\n[2]: 形象易懂讲解算法I——小波变换 https://zhuanlan.zhihu.com/p/22450818\n[3]: David K Hammond, Pierre Vandergheynst, and Re ́mi Gribonval. Wavelets on graphs via spectral graph theory. Applied and Computational Harmonic Analysis, 30(2):129–150, 2011.\n","date":1630872421,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1630872421,"objectID":"9d8f2fc5b1b8902dfb125d62d0cec1f5","permalink":"https://example.com/post/wavelet/","publishdate":"2021-09-05T20:07:01Z","relpermalink":"/post/wavelet/","section":"post","summary":"图小波神经网络的解析","tags":["Graph","Wavelet","Neural Network"],"title":"Graph wavelet nerual network","type":"post"},{"authors":null,"categories":null,"content":"图信号的采样理论 tags: \u0026#39;图信号处理\u0026#39; \u0026#39;采样\u0026#39; 论文信息 Paper: [IEEE Transactions on Signal Processing 63 (24)] Discrete signal processing on graphs: Sampling theory [1]Link: https://arxiv.org/pdf/1503.05432 背景梳理 对于一个普通的离散时间信号，采样和恢复是极为重要的议题。在传统的信号与系统以及数字信号处理理论中，如果一个信号的采样率高过其最高频率的两倍，我们就能够完美的恢复原始信号。这是信号处理领域著名的奈奎斯特采样定理：\n上式中表示采样频率，被采样信号中的最高频率分量。 自然而然，我们希望将采样的完美恢复条件扩展的图信号处理当中。例如社交网络的分析当中，如果能够采样部分用户数据获得完整的全局信息，自然能为图信号处理带来新的优势。本文作者及其敏锐地发现了采样理论在时间信号和图信号中的联系和不同，发现了在图傅立叶变换下限带的图信号，完美的恢复是可能的。采样后的信号系数将形成一个新的图信号，其对应的图结构保留了原始图信号的一阶差分。对于一般图，作者提出了最优采样算子，以保证完美的恢复和对噪声的鲁棒性；对于图傅立叶变换是Frames With Maximal Robustness to Erasures的图以及 Erdős-Rényi图，随机采样后可以完美恢复的概率是非常高的。 本文的主要贡献包括以下三点： • 提出了一种新颖的图形信号采样框架，通过使用线性代数中的简单工具解决了复杂的采样问题； • 提出了一种通过保留原始图形信号中的一阶差分来对图形进行采样的新方法； • 一种在图上设计采样算子的新方法。\n图的基本定义 图移位操作 对于一个图上的离散信号处理，我们用来表示一个具有复杂结构的图，其中是节点的集合，是图移位矩阵，也就是图的邻接矩阵，其表征了图的连接关系，可表示有向图和无向图（标准的图拉普拉斯矩阵式是只能表述无向图的关系）。为了保证以为操作数值尺度合理，我们将移位矩阵归一化使其满足。\n图信号 在给定的图表征中，图信号被定义为图节点上的映射，它将信号系数分配给节点。 一旦节点顺序固定，图信号可以写成一个向量:\n其中第n个信号洗漱表征节点上的响应。\n图傅立叶变换 通常来说，傅立叶变换对应于使用具有滤波不变性的基元素对信号进行分解。在这里，这个基是图移位矩阵的特征基（或者，如果完整的特征基不存在，则是的Jordan特征基）。为简单起见，假设具有完整的特征基并且的分解为:\n其中，矩阵V的行为特征矩阵A的特征向量。而是由矩阵的特征值构成的对角矩阵。 接下来，我们定义图信号的傅立叶变换为：\n逆变换为：\n向量表示信号在该组特征基上的系数，描述图形信号的频率内容。图傅立叶逆变换通过组合由信号图傅立叶变换的系数加权的图频率分量，从其频率内容重建图信号。\n采样的基本定义 采样和重建 我们希望从一个图信号采样M个系数来产生一个采样信号，其中表示采样索引，。 而插值则指的是将转为，该恢复信号能与原始信号完全或者近似相等。采样操作可以用一个从到的线性映射表示，我们定义为:\n对应的插值操作则是从到的线性映射。我们将这两个过程写作矩阵形式：\n带限信号 我们将带限图信号定义为： 当存在一个使得图信号的的图傅立叶变换满足：\n最小的符合条件的被称为信号的带宽。一个非带限的图信号被称作是全带图信号。 请注意，此处的带限图信号不一定意味着低通或平滑。 由于我们没有指定频率的顺序，我们可以重新排序特征值并置换图傅立叶变换矩阵中的相应特征向量以选择图傅立叶域中的任何波段。 只有当我们按降序对特征值进行排序时，带限图信号才是平滑的。 这里的带限限制等效于限制已知支持的图傅立叶域中非零信号系数的数量。这种概括对于表示非光滑图信号可能有用。 特别需要注意的是：在定义带宽时，我们关注图频率的数量，而之前的工作 [2] 则关注图频率的值。使用图频率值有两个缺点：\n(a)在考虑图频率值时，我们忽略了图的离散性；因为图频率是离散的，所以同一图上的两个截止图频率可以导致相同的带限空间。例如，假设一个图的图频率为 0、0.1、0.4、0.6 和 2；当我们将截止频率设置为 0.2 或 0.3 时，它们会导致相同的带限空间；(b) 图频率值不能在不同图之间进行比较。由于每个图都有自己的图频率，因此两个图上截止图频率的相同值可能意味着不同的事情。例如，一个图的图频率为 0、0.1、0.2、0.4 和 2，另一个图的图频率为 0、1.1、1.6、1.8 和 2；当我们将截止频率设置为 1 时，即我们保留所有不大于 1 的图频率，第一个图保留了四个图频率中的三个，第二个图仅保留了四个图频率中的一个。因此，图频率的值不一定能直接直观地理解带限空间。使用图形频率数量的另一个关键优势是建立与线性代数的关系，允许使用线性代数中的简单工具对带限图形信号进行采样和插值。 采样恢复的条件 从之前采样和恢复的矩阵表达式中我们可以发现，要想采样后的信号能够完美恢复，则必须满足\n这意味着相乘的结果为单位矩阵。\n接下来我们从代数的角度来看这个问题，首先我们定义：\n其中表示矩阵的前K行。完美恢复只有在：\n的时候才会达成，其中是一个的单位矩阵。 当 时，，因此，永远不可能是单位矩阵。 对于是单位矩阵，当 时， 是 的逆； 当 时，它是的伪逆，其中冗余可用于减少噪声的影响。 为简单起见，我们只考虑 和 可逆。 当 时，我们只需从 个采样信号系数中选择 个，以确保样本大小和带宽相同。\n采样后的图信号 首先补充一个定义：（为保证描述准确，这里使用英文原文） Definition: The set of graph signals in with bandwidth of at most is a closed subspace denoted , with as in 接下来我们考虑的情况： 当采样操作满足前文所述恢复条件时，对所有的,有下式：\n其中表示的前个系数。结合之前所述我们可以得到：\n这说明采样信号和可以构成一个傅立叶对，进而我们得到这个信号是关联于图移位矩阵的一个图信号：\n采样后图信号的特性 我们认为是采样后的图移位矩阵。在采样过程中，究竟什么信息被所保存下来？接下来本文将讨论这个问题，首先给出结论：\n证明如下：\n由于项表征的是原始信号和移位信号之间的差，这也被称作的一阶差分。而则表征的是采样过后信号的一阶差分。当然这里也可以用p阶范数，总之是用来表示图信号的平滑程度。当使用采样图来表示采样信号系数时，我们丢失了采样节点与所有其他节点之间的连通性信息； 尽管如此，仍然保留采样索引处的一阶差分信息。\n合格采样算子的采样 如前文所述，只有合格的采样算子才能完美恢复带限图形信号。由于合格的抽样算子是通过图结构设计的，该设计包括在中找到个线性独立的行，这提供了多种选择。在本节中，我们提出了一种通过最小化一般图的噪声影响来设计合格采样算子的最佳方法。 然后我们表明，对于一些特定的图，随机抽样也导致高概率的完美恢复。\n实验设计信号 我们考虑在采样过程中引入噪声的模型如下：\n其中是一个可恢复的采样，\n为了限制误差范围\n从上式中可以看出，因为和是确定量，要想让上界变小，只能使变小。这等价于最大化的最小化奇异值。可将该优化问题定义为：\n可以用以下贪心算法获得最优采样算子： 随机采样 这里我们着重介绍Erdo ̋s-Re ́nyi图（下文用E图代指）。 Erdo ̋s-Re ́nyi 图是通过随机连接节点构建的，其中每条边都包含在图中，概率 p 独立于任何其他边。我们旨在证明通过随机采样 K 个信号系数，对应的 Ψ V(K) 的奇异值是有界的。 我们让图移位算子表示一个E图，节点之间的连接彼此独立，概率为，同时是某个正函数。我们让V为A的特征向量组成的矩阵（）,同时是采样数M满足：\n其中为正常数，有以下结论\n（证明位于参考文献[3]的定理1.2）\n根据上式的结论，我们可以得出结论：令按上式定义。可以以的概率，使的奇异值落在到中（有上下界）。 证明如下： 首先根据上式，可得：\n于是，对于所有的,有\n从上式中，我们看到的奇异值有很高的概率有界。这表明 ΨV(K) 具有高概率满秩； 换句话说，当我们随机采样足够数量的信号系数时，对于E图信号，很有可能实现完美的恢复。 对于该结论，作者进行了仿真实验 上图显示了 50 和 500 大小的图在 100 次随机测试中的平均成功率。 当我们固定图大小时，在E图中，成功率随着连接概率的增加而增加，即两节点越容易产生连接，得到合格抽样算子的概率越高。 当我们比较节点间连接概率相同的的不同大小图时，采样恢复成功率随着大小的增加而增加，即较大的图大小导致获得合格抽样算子的概率更高。模拟结果表明，当图上存在更多连接时，更容易满足满秩假设。直觉是，在连接概率较高的较大图中，节点之间的差异较小，即每个节点具有相似的连通性，并且没有优先选择一个而不是另一个。\n总结 这篇文章获得了2018年IEEE信号处理协会最佳年轻作者论文奖，斯坦福大学的美国工程院院士Goldsmith教授在引用本文时指出，该工作得到了图上带限信号的最优采样策略。本文将基础代数工具运用至图信号处理领域并给出了寻找optimal operator的贪心算法，在图信号处理的发展中起到了相当重要的作用。由于篇幅所限，在这里我们对部分内容进行了省略和缩写，大家感兴趣的话可以阅读原文，原文中在随机采样部分还有对Frames with Maximal Robustness to Erasures的讨论，同时也有不少图信号采样理论结合离散时间信号采样以及压缩感知等内容。\n参考文献 [1]: Chen, Siheng, et al. \u0026#34;Discrete Signal Processing on Graphs: Sampling Theory. in IEEE transactions on signal processing 63.24 (2015): 6510-6523.\n[2]: A. Anis, A. Gadde, and A. Ortega, “Towards a sampling theorem for signals on arbitrary graphs,” in Proc. IEEE Int. Conf. Acoust., Speech Signal Process., May 2014, pp. 3864–3868.\n[3]: E. J. Cande and J. Romberg, “Sparsity and incoherence in compressive sampling,” Inverse Problems, vol. 23, pp. 110–134, 2007.\n","date":1627248990,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1627248990,"objectID":"99817983afb8dbcf2e886e159ea9b6e3","permalink":"https://example.com/post/graphsample/","publishdate":"2021-07-25T21:36:30Z","relpermalink":"/post/graphsample/","section":"post","summary":"Discrete signal processing on graphs, Sampling theory","tags":["Graph","Signal Processing","Sampling"],"title":"图信号的采样理论","type":"post"},{"authors":null,"categories":null,"content":"LVI-SAM:基于SAM的紧耦合激光雷达-视觉-惯导里程计 论文信息 论文标题： LVI-SAM: Tightly-coupled Lidar-Visual-Inertial Odometry via Smoothing and Mapping 论文来源： ICRA 2021 论文链接： https://arxiv.org/abs/2104.10831 代码： https://github.com/TixiaoShan/LVI-SAM\n简介 作者提出了一个基于SAM的激光雷达-视觉-惯性测距框架 LVI-SAM，它实现了高精度和鲁棒的实时状态估计和地图构建。 LVI-SAM 建立在因子图(factor graph)之上，由两个子系统组成：视觉惯性系统 (VIS) 和激光雷达惯性系统 (LIS)。这两个子系统以紧耦合的方式设计，其中 VIS 利用 LIS 的估计来进行初始化。通过使用激光雷达的扫描数据提取视觉特征的深度信息，提高了 VIS 的精度。反过来，LIS 利用 VIS 估计进行初始猜测以支持扫描点的匹配。闭环检测首先由 VIS 识别，然后由 LIS 进一步细化。 LVI-SAM 也可以在两个子系统之一出现问题时正常使用，从而提高其在无纹理和无特征环境中的稳健性。 LVI-SAM 对从多个平台在各种规模和环境中收集的数据集进行了广泛评估。\n特点 1、实现了一个紧耦合的激光-视觉-惯导系统，通过因子图同时完成了多传感器融合和全局优化（包含回环检测）两项任务。 2、通过故障检测机制，绕过出现问题的子系统(LIS或VIS)，提高了整个系统的鲁棒性。\n算法框架 如算法流程框图所示，LVI-SAM系统主要分为基于视觉+惯导和点云+惯导两个系统。其中，VIS系统作者使用经典的VINS-Mono作为baseline。\nVIS 该视觉系统的特征点通过角点来进行提取，跟踪算法使用Lucas-Tomasi算法。与VINS-Mono不同之处在于，该VIS系统初始化时，会将激光雷达帧与视觉数据配准后获得一个稀疏的深度图，该深度图可用于辅助获得视觉特征点的深度信息。之后再通过优化视觉和IMU的测量联合残差得到视觉里程计。\n初始化 由于在初始化时解决高度非线性问题，基于优化的 VIO 通常会出现发散。初始化的质量在很大程度上取决于两个因素：初始传感器运动和 IMU 参数的准确程度。在实践中，作者发现当传感器以小速度或恒定速度行进时，VINS-Mono经常无法初始化。这是因为当加速度激励不够大时观察变得十分困难。IMU 数据中噪声和偏差的比重过高，它们会影响原始加速度和角速度测量。在初始化时对这些参数的正确猜测有助于优化更快地收敛。 为了提高LVI-SAM中的 VIS 初始化的鲁棒性，作者利用了来自 LIS 的估计系统状态 $x$ 和 IMU 偏差$b$。因为深度可以从激光雷达直接观察到，作者首先初始化 LIS 并获得 $x$ 和 $b$。然后根据图像时间戳对它们进行插值并将它们关联到每个图像关键帧。这里作者假设了IMU偏差在两个图像关键帧之间是恒定的。最后，来自 LIS 的估计$x$和$b$被用作VIS初始化的初始猜测，这显着提高了初始化速度和鲁棒性。可以在补充视频中找到使用和不使用LIS帮助的VIS初始化的比较。\n特征深度关系 VIS完成初始化后，目标是使用VIS视觉里程计配准激光雷达的扫描结果。我们都知道激光雷达扫描的点云结果是稀疏的。为解决这个问题，作者将若干激光雷达帧聚合在一起，试图获得一个稠密的深度图像。作者将特征点与激光雷达获得的点云转换至同一个以相机为球心的单位球上。在该球内使用K-D tree来寻找球坐标系下距离图像特征点最近的三个激光雷达深度点，并将特征点的深度表示为特征点与球心的连线与之前找到的三个激光雷达深度点形成的平面的交点的深度。\n失败检测 由于剧烈运动、光照变化和无纹理环境，VIS 会出现失败情况。 当机器人进行剧烈运动或进入无纹理环境时，跟踪特征的数量会大大减少。 不足的特征可能会导致优化问题无法收敛。当 VIS 出现故障时，估计会产生很大的IMU偏差。因此，当跟踪特征的数量低于阈值或估计的 IMU 偏差超过阈值时，LVI-SAM报告VIS失败。 该系统需要主动故障检测，以便其故障不会破坏LIS的功能。 一旦检测到故障，VIS会重新初始化并通知LIS。\n回环检测 LVI-SAM使用DBoW2算法进行闭环检测。对每个新的关键帧，提取BRIEF描述子，并与之前的进行比较。通过DBoW2获得的候选者，将会发给LIS进行进一步验证。\nLIS 激光模块作者基于自己此前的工作LIO-SAM，使用因子图进行全局位姿优化。通过IMU预积分、视觉里程计、激光雷达里程计、闭环检测四种约束来优化结果。作者对激光雷达使用了一个关键帧滑动窗来保证计算复杂度。当机器人产生较大位移时，即丢弃关键帧之间的帧。选择了新关键帧后，如图所示，则在因子图中增加一个新的机器人状态$x$节点。\n初始估计 在 LIS 初始化之前，作者假设机器人从零速度的静态位置开始。然后整合原始IMU测量，假设偏置和噪声为零值。两个激光雷达关键帧之间的综合平移和旋转变化产生了扫描匹配的初始猜测。作者发现当初始线速度小于 $10 m/s$ 且角速度小于 $180^{\\circ}/s$ 时，这种方法可以成功初始化系统。 LIS 初始化后，我们在因子图中估计 IMU 偏差、机器人位姿和速度。然后我们将它们发送到 VIS 以帮助其初始化。 LIS 初始化后，便可以从两个来源获得初始猜测：具有校正偏差的集成 IMU 测量值和 VIS。当可用时，作者使用视觉惯性里程计作为初始猜测。如果 VIS 报告失败，系统将切换到 IMU 测量以进行初始猜测。这些程序在纹理丰富和纹理少的环境中提高了初始猜测的准确性和鲁棒性。\n失败检测 尽管激光雷达可以在远距离捕获环境的精细细节，但它仍然会遇到扫描匹配受到不良约束的场景。作者们采用 “On Degeneracy of Optimization-based State Estimation Problems” 中的方法进行 LIS失败检测。\n实验 作者使用自己采集的数据集进行了消融实验，其中A1：不包含LIS；A2：不包含VIS；A3：LIS与VIS都用，测试VIS中深度优化的作用；A4：包含闭环检测 作者在Jackal dataset和Handheld dataset中对比了LVI-SAM和目前的一些SOTA方法，LVI-SAM在两个数据集上都完成得很好。 参考文献 [1]: Shan T, Englot B, Ratti C, Rus D. LVI-SAM: Tightly-coupled Lidar-Visual-Inertial Odometry via Smoothing and Mapping. arXiv preprint arXiv:2104.10831. 2021 Apr 22.\n[2]: Qin, Tong, Peiliang Li, and Shaojie Shen. “Vins-mono: A robust and versatile monocular visual-inertial state estimator.” IEEE Transactions on Robotics 34, no. 4 (2018): 1004-1020.\n[3]: Shan T, Englot B, Meyers D, Wang W, Ratti C, Rus D. Lio-sam: Tightly-coupled lidar inertial odometry via smoothing and mapping. arXiv preprint arXiv:2007.00258. 2020 Jul 1.\n","date":1623510488,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1623510488,"objectID":"6443a3db378d917ca1cde34ed870a3f0","permalink":"https://example.com/post/lvi-sam/","publishdate":"2021-06-12T15:08:08Z","relpermalink":"/post/lvi-sam/","section":"post","summary":"Tightly-coupled Lidar-Visual-Inertial Odometry via Smoothing and Mapping","tags":["SLAM","RGB","PointCloud","IMU"],"title":"LVI-SAM","type":"post"},{"authors":[],"categories":[],"content":"Create slides in Markdown with Wowchemy Wowchemy | Documentation\nFeatures Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides Controls Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click PDF Export Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026#34;blueberry\u0026#34; if porridge == \u0026#34;blueberry\u0026#34;: print(\u0026#34;Eating...\u0026#34;) Math In-line math: $x + y = z$\nBlock math:\n$$ f\\left( x \\right) = ;\\frac{{2\\left( {x + 4} \\right)\\left( {x - 4} \\right)}}{{\\left( {x + 4} \\right)\\left( {x + 1} \\right)}} $$\nFragments Make content appear incrementally\n{{% fragment %}} One {{% /fragment %}} {{% fragment %}} **Two** {{% /fragment %}} {{% fragment %}} Three {{% /fragment %}} Press Space to play!\nOne Two Three A fragment can accept two optional parameters:\nclass: use a custom style (requires definition in custom CSS) weight: sets the order in which a fragment appears Speaker Notes Add speaker notes to your presentation\n{{% speaker_note %}} - Only the speaker can read these notes - Press `S` key to view {{% /speaker_note %}} Press the S key to view the speaker notes!\nOnly the speaker can read these notes Press S key to view Themes black: Black background, white text, blue links (default) white: White background, black text, blue links league: Gray background, white text, blue links beige: Beige background, dark text, brown links sky: Blue background, thin dark text, blue links night: Black background, thick white text, orange links serif: Cappuccino background, gray text, brown links simple: White background, black text, blue links solarized: Cream-colored background, dark green text, blue links Custom Slide Customize the slide style and background\n{{\u0026lt; slide background-image=\u0026#34;/media/boards.jpg\u0026#34; \u0026gt;}} {{\u0026lt; slide background-color=\u0026#34;#0000FF\u0026#34; \u0026gt;}} {{\u0026lt; slide class=\u0026#34;my-style\u0026#34; \u0026gt;}} Custom CSS Example Let’s make headers navy colored.\nCreate assets/css/reveal_custom.css with:\n.reveal section h1, .reveal section h2, .reveal section h3 { color: navy; } Questions? Ask\nDocumentation\n","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1549324800,"objectID":"0e6de1a61aa83269ff13324f3167c1a9","permalink":"https://example.com/slides/example/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/slides/example/","section":"slides","summary":"An introduction to using Wowchemy's Slides feature.","tags":[],"title":"Slides","type":"slides"},{"authors":["Zixing Lei"],"categories":[],"content":"从网络层视角看车载通信 tags: \u0026#39;IOT\u0026#39; \u0026#39;自动驾驶\u0026#39; \u0026#39;通信\u0026#39; 论文信息 Paper: Vehicular Communications: A Network Layer PerspectiveLink: https://ieeexplore.ieee.org/abstract/document/8354811 车载通信的基本介绍 应用领域 安全 第一种类型是车辆运动状态信息共享，通过在车辆间共享安全信息，降低事故发生概率。例如在车辆间共享实时的位置，速度，方向信息来辅助司机或者自动驾驶系统的判断和决策，做出类似变道，转向等操作来避免碰撞。 第二种类型是事件驱动型安全信息。例如紧急的车辆状态警告、交通状况警告、追尾警告。事件驱动的安全信息，由涉及或发现危险情况（如紧急制动器或突然车道变化）的某些车辆产生的安全信息，以帮助其他车辆获得实时情境意识并检测可能的危险。如图1所示，共享车辆之间的碰撞和后端追尾警告信息可以帮助避免在若干场景中的事故 非安全性应用 通过在移动车辆之间的共享信息，可以提供增值服务，例如交通管理和信息娱乐支持，以增强通勤者的舒适度。大多数流量管理应用程序都是为了减少交通拥堵而来改善交通流量并节省通勤者的旅行时间。例如，通过共享有关移动车辆之间的流量监控和道路条件的信息，可以应用流量管理算法，依据车辆的目的地等信息进行路线规划，并提高交通灯指挥效率，从而减少交通拥塞。不同于交通管理，信息娱乐支持应用主要关注提供旅行者位置的服务和娱乐。例如，信息娱乐支持应用程序可以提供位置信息，例如关于司机或乘客需要相关服务的燃料站，停车，餐厅和酒店等信息。此外，信息娱乐支持应用还可以提供移动车辆的互联网接入下载多媒体娱乐信息。\n车载通信特点 在车辆网络中，V2V通信基本上通过应用移动自组网（MANETs）的原理来执行，即，为数据交换自发地创建无线通信。 除了类似于MANET [2]的一些特性之外，例如自组织和管理，短到中等传输范围，全向广播和低带宽，车辆网络由于其移动节点而具有自己独特的特性。 根据他们是否有利于信息交换，这些特征被分为有害和有益的特征。\n有害特征 有害特征包括以下三点：\n高度的机动性： 由于车辆通常处于移动状态，甚至是高速移动状态，这导致无线连接必然经常中断，车辆间有效通信时间很短。此外，它还将导致网络拓扑动态地改变，进一步增加了车辆间通信的挑战。严格的延迟限制： 在某些车辆网络应用程序中，如安全应用和一些信息应用，由于高度的移动特征，需要在特定的时间限制内成功完成信息交换，以避免交通事故并确保信息服务的质量。注意此处提到的延迟是从源到目的地的最大延迟，而不是车辆网络的平均延迟。复杂的通信环境： 车载网络通常应用于三种通信环境。第一个是一维通信环境，例如高速公路交通场景。尽管高速公路上的车辆总是比其他场景中移动得更快，但由于移动方向直接且速度相对固定，所以相对简单。第二个是二维通信环境。一个典型的例子是城市交通场景，与高速公路场景相比，它更为复杂。大多数城市地区的街道往往因交叉路口而被分成许多路段。因此，对于处于不同路段的两辆行驶的车辆，由于交叉路口周围的障碍物，例如建筑物和树木，可能不存在直接的通信链路。此外，城市地区的车辆密度总是较高，这意味着通信范围内的通信链路更多，对频谱资源占用概率有显着影响。最后一个是三维通信环境，如高架桥。对于高架桥中的车辆，不同物理空间层的通信链路使这种类型的环境最为复杂。 有益特征 很弱的能耗限制： 这是显而易见的路径可预测： 车辆在通常情况下仅限于在道路上行驶，这使得在可以获得路线图和车速信息的情况下，可以为自己甚至为其他车辆预测行驶路线。驾驶路线预测在车辆网络的路由协议设计中起着重要作用，尤其是在解决高机动性带来的挑战时。 人类驾驶车辆的网络设计 MDVNETs的技术简介 除了导航系统外，大多数现代车辆都配备了DSRC（专用短程通讯协议）、蜂窝、Wi-Fi、White-Fi 等，使车载网络能够改善驾驶体验增加安全性。 在下文中，我们回顾了 MDVNET 中四种广泛应用的通信技术。 请注意，此处不考虑可用于支持车载通信或/和交通状况监测的超宽频(UWB) 和蓝牙（Bluetooth）。\nDSRC DSRC是一种设计用于车辆与车辆，车辆与基础设施之间的短程通信协议，基于IEEE 802.11p,是由Wi-Fi标准的802.11拓展而来。作为唯一专门提供给车联网的通信协议，DSRC具有以下优点：\n· 指定许可带宽： 1999年十月起，联邦通信委员会(FCC)将5.9GHz频段的中的75MHz被分配给了以DSRC为基础的智慧交通系统\n· 高度可靠性： 基于DSRC的无线连接可以在高机动性以及极端天气条件下使用。\n· 安全应用优先： DSRC总共的75MHz带宽被分为了一个控制信道和六个服务信道，每个带宽为10MHz，剩下5MHz作为保护带宽。\n· 通信安全和隐私： 信息授权和隐私标准由IEEE 1609.2标准提供。 同样，DSRC也有一些缺点：\n· 频谱资源极为有限： 在大面积传播安全信息时可能会出现广播风暴，尤其是在车辆密度较高的情况下。\n·· 连接性差且寿命短： V2V 和 V2I 连接性差且寿命短。 短暂的 V2V 连接总是发生在车辆密度低的环境中，若车辆数量太少，无法将信息传播到所有目的地车辆。特别是DSRC只支持300m距离内的通讯，进一步加剧了V2I的连接性。\n蜂窝网络 这是大家非常熟悉的1G、2G、3G、LTE等通讯标准，将其应用在车联网领域可以显著提升通信容量。蜂窝网络可以支持在一个小单元中的多辆汽车的车间通信，此外，蜂窝技术中的信道和传输模式，即专用/通用模式和单播/广播/多播下行链路传输模式，可以帮助减少传输延迟并提高高车辆密度的通信环境的容量。 设备到设备 (D2D) 通信可以在两个车辆用户之间提供短距离直接链接以重用频谱，从而缓解有限无线电频谱资源带来的问题 当然，蜂窝网络的缺点也是显而易见的。首先蜂窝网络的成本远高于其他网联方式。同时蜂窝网络容易受到车联网之外的蜂窝终端的影响。\nWi-Fi Wi-Fi是建立在IEEE802.11标准上的一种无线局域网标准。配备 Wi-Fi 无线电或支持 Wi-Fi 的移动设备（如手机），车辆可以在通过 Wi-Fi 接入点覆盖范围内行驶时访问互联网。 Wi-Fi 技术的明显优势包括较低的每比特成本、极其广泛的全球部署和更高的峰值吞吐量，这有利于一些具有高数据传输速率的车载应用，例如信息娱乐应用。然而，由于每个 Wi-Fi 接入点 (AP) 的覆盖范围有限以及车辆的高移动性，Wi-Fi 技术在车载网络中受到间歇性连接的影响，因此，在这种情况下，切换方案对 Wi-Fi技术尤为重要。\nWhite-Fi 这是美国 FCC 创造的一个术语，用于描述允许未经许可的用户访问 54 到 790 MHz 之间的 VHF/UHF 频段中的电视空白频谱的通信。启用 White-Fi 的车载网络可以通过将部分数据流量从 DSRC 频段或蜂窝频段卸载到 TV 频段来提高传播能力。此外，与 Wi-Fi 使用的 2.4 GHz 射频不同，电视空白频谱位于较低的频率范围内，允许信号更好地穿透墙壁并比较高的频率范围传播得更远。因此，White-Fi 技术可以提供相对长距离的通信以提高传输效率。例如，应用White-Fi 进行长距离传播以避免多跳传输可以减少一些安全相关信息的传输延迟。然而，启用 White-Fi 的车载通信对现有电视频段用户产生潜在干扰，这可能会给保护现有服务带来挑战。\nMultiple technologies interworking 如前所述，已经表明，应用于车载网络的单一技术总是有其自身的局限性。因此，DSRC、蜂窝、Wi-Fi 和 White-Fi的上述优点和缺点推动了建立异构 MDVNET 的工作，而不是通过单一通信技术建立支持车载通信的同构 MDVNET。在异构 MDVNETs 中，车载通信至少有两种通信技术支持，城市地区异构 MDVNET 的例子如图 2 所示，其中 V2X 是指车辆到万物的通信，包括 V2V和 V2I 通信。但如何为每条通信链路选择适用的技术，实现不同技术之间的无缝切换仍然具有挑战性。 路由机制 单播路由机制 它指的是从一个通信实体到另一个通信实体的一对一传输。 在 MDVNET 中，单播的主要目标是通过单跳/多跳无线通信将数据包从单个源车辆传输到另一个单个目标车辆，方法是使用“逐跳”机制。其主要包括贪婪法和机会法两种类型：\n· 贪婪法： ：在贪婪单播路由协议中，源车辆将数据包转发到其最外面的邻居（下一跳中间车辆），然后中间车辆将这些数据包转发到其最外面的邻居（第二跳中间车辆），直到目的地。也就是说，基于贪婪的单播路由协议中的前向决策是基于车辆的地理信息做出的。当使用“逐跳”机制时，基于贪婪的单播路由协议在一些简单的通信场景中工作良好，例如在笔直交通道路上的车辆。然而，对于总是有很多交叉点的城市地区，贪婪的存储转发路由协议更适合支持延迟容忍的非安全应用。例如，通过利用地图信息的可用性，他们可以通过基于物理位置、速度、方向、动态交通密度和曲线度量距离等信息选择下一跳来减少通信延迟。\n· 机会法： ：机会单播路由协议支持无线网络在频繁断开连接的场景中运行，例如车载网络。在机会单播路由协议中，来自源的数据包机会性地传送到目的地，其中\n中间车辆应该有能力存储和携带接收到的数据包并以“存储和转发”的方式执行；前向决策是针对不同区域的车辆独立做出的，以最终传递几乎没有目的地位置信息或没有目的地位置信息的数据包；可以并行传输源数据包的多个副本，以增加至少一个数据包副本被传送的概率。 设计单播路由协议的主要挑战包括如何有效地共享这些基本信息，减少通信延迟和数据包丢失，以及在存在大量单播路由请求时处理路由冲突。\n多播路由机制 单播中一传一变化为一传多。\n广播路由机制 继续增加到向所有通信范围内的车辆广播。\n基于集群的路由机制 基于集群的路由协议：是一种将车辆按照一定的规则分成不同的集合（集群），从每个集合中选择一个车辆作为集群头（cluster head, CH），其余的称为集群成员（cluster memebers, CM）的路由方法 . 请注意，单播、多播和广播是三种基本路由协议，可用于描述车载网络中的所有路由方法。 基于集群的路由协议是单播、多播和广播的组合。 例如，在同一个集群中，CM 向其 CH 单播数据包，CH 向其所有成员广播数据包并将数据包多播到道路基础设施或其他 CH，道路基础设施将数据包单播到一个 CH 或多播数据包到其内的 CH。 图三形象地表示了以上路由机制。 传递策略 在 MDVNET 中，切换是高效可靠的车辆通信的主要问题。 车辆经常进出其他车辆和基础设施的通信范围，导致 V2V 和 V2I 通信链路经常断开以及动态变化的网络拓扑。 切换策略旨在为 MDVNET 中的车辆提供无缝通信，同时降低成本、切换延迟和数据包丢失等，并在过去几年引起了很多关注。 切换策略有两种类型：水平切换和垂直切换，这取决于使用的是相同还是不同的无线接入技术。\n水平切换 当相同的无线接入技术应用于两个连接点时，它用于将数据传输会话从一个连接点传输到另一个连接点。\n垂直切换 当两种不同的无线接入技术应用于这两个连接点时，它用于将数据传输会话从一个连接点传输到另一个连接点。\n自动驾驶车辆的网络设计 ADVNET（AUTOMATED DRIVING VEHICULAR NETWORKS）如图4所示，可分为以下三种： Free ADVNET，convoy-based ADVNETs, 以及platoon-based ADVNETs 与MDVNETs不同，由于以下原因，高移动性和复杂的通信环境对ADVNETs的影响更为显著： · 延迟和可靠性要求更高 · 在安全性上有很高的要求 · 计算资源的管理和分配更加复杂\nADVNET的通信结构 对于Free ADVNET来说，广播通信是主要的方式，即车辆将其信息广 …","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1567641600,"objectID":"828a84ecd177336d3405395a108c42fd","permalink":"https://example.com/post/v2vnetwork/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/post/v2vnetwork/","section":"post","summary":"车载网络如何赋能多智能体协作感知","tags":[],"title":"从网络层视角看车载通信","type":"post"},{"authors":["Zixing Lei"],"categories":[],"content":"协同感知的策略设计 论文信息 [ECCV 2020] V2VNet: Vehicle-to-Vehicle Communication for Joint Perception and Prediction https://link.springer.com/chapter/10.1007/978-3-030-58536-5_36\n[ICRA 2020] Who2com: Collaborative Perception via Learnable Handshake Communication https://ieeexplore.ieee.org/abstract/document/9197364\n[CVPR 2020] When2com: Multi-Agent Perception via Communication Graph Grouping https://openaccess.thecvf.com/content_CVPR_2020/html/Liu_When2com_Multi-Agent_Perception_via_Communication_Graph_Grouping_CVPR_2020_paper.html\n背景介绍 在例如机器人编队，无人驾驶等依靠感知系统的场景中，单体感知技术受到视距受限，物体遮挡等物理条件的制约，对整个场景的感知存在较大不足。\n单体感知受限于遮挡等物理限制 而随着通信技术的不断发展，V2V，V2X的通信协议的稳步建立为多智能体协同感知提供了基础条件。多智能体系统由于拥有更大的感知覆盖面积，更多的感知角度，相对于单智能体系统，在感知任务上有时很有优势，它们往往并对某一个或部分智能体的失败更加鲁棒，同时能够克服视距受限和物体遮挡的制约。\n通过协同手段减轻遮挡的影响 有些研究开始探索多智能体系统下的协同感知问题。V2VNet[1]探索了车对车通信场景下，通过聚合一定区域内不同位置车辆的感知信息，使得单个车辆 得以克服遮挡和远距离带来的感知困难。Who2com[2]，When2com[3]在 3D 场景下的 2D 分割任务以及 3D 物体识别任务上，实现了多智能体系统下具有较高通信效率的协同感知。接下来我们将具体介绍这三篇文章所提出的方法。\nV2VNet: Vehicle-to-Vehicle Communication for Joint Perception and Prediction Which Information should be Transmitted V2VNet提出，发送 perception and prediction (P\u0026amp;P) 网络的中间特征可以实现带宽占用和性能指标的两全其美。该流程可以描述为：首先，每辆车处 理自己的传感器数据并计算其中间特征表示。这些特征被压缩并广播到附近的self-driving vehicles (SDVs)。 然后，每个SDV使用从其他SDV接收到的消息来更新其P\u0026amp;P网络的中间表示。这将通过额外设计的网络进一步处理，以产生最终的感知和运动预测输出。\nV2VNet系统整体架构 Leveraging Multiple Vehicles 如何将多辆车的感知结果融合在一起呢？V2VNet给出了这样的架构：\nLidar Convolution Block 首先使用Pixor[4]架构对3D原始点云数据进行处理。从雷达数据中提取特征，并将其转换到鸟瞰图上。在这个过程中，V2VNet会将最近的5帧点云点聚合到一个个15.6的立方体中，并对3D体素进行卷积，得到规模的特征图。\nCompression 对于车联通信这样的应用场景，如何降低协同感知对于通信带宽的占用也是至关重要的。因此V2VNet将图像压缩领域技术迁移到V2V特征压缩，在文中使用的是variational image compression algorithm[5]，卷积网络在先验的帮助下学习压缩特征表示。 然后通过熵编码用很少数据量对特征进行量化和无损编码。 这个压缩模块是可微可训练的，这允许V2VNet的方法学习如何在最小化带宽的同时保留特征图信息。\nCross-vehicle Aggregation 接下来，V2VNet需要把来自不同SDV，处于不同空间位置的特征进行聚合。其提出使用一个全连接GNN来对此进行建模。每个SDV上均建立一个包含其通信范围内所有SDV的图，其计算在本地SDV上进行。\n聚合算法的伪代码 在该算法中，作者先使用一个CNN网络对其进行延时补偿，之后使用一个GNN message passing结构，V2VNet认为，由于可通信的SDVs位于邻近空间区域，因此节点表示将具有重叠的视野。如果V2VNet能够很好地转换表示并在视场重叠的节点之间共享信息，便可以增强SDV对场景的理解并产生更好的输出。如上文V2VNet整体架构图所示，首先应用相对空间变换 来转换第i个SDV的中间特征，以向第 k 个SDV发送 GNN 消息。然后V2VNet使用 CNN 对两个节点完成了空间对齐的特征图执行联合推理。最终修改后的消息按照聚合算法的第7行进行计算，其中T通过双线性插值应用特征状态的空间变换和重采样，并且 掩盖了视场之间的非重叠区域。 请注意，通过这种设计，V2VNet的特征保持了空间对应性。\n接下来，V2VNet通过一个mask-aware permutation-invariant函数 在每个节点聚合接收到的消息，并使用ConvGRU来更新节点状态（聚合算法第 8 行），其中 是 网络中节点i的相邻节点,是均值算子。mask-aware accumulation operator确保只考虑重叠的视野。 此外，节点更新中的门控机制可以根据接收 SDV 的当前状态对累积的接收消息进行信息选择。 在最后一次迭代之后，多层感知器输出更新的中间特征（聚合算法第 11 行）。V2VNet重复这个消息传播方案并进行固定次数的迭代。\nWho2com: Collaborative Perception via Learnable Handshake Communication When2com和Who2com两项工作均由Georgia Tech Zsolt Kira组完成。我们先介绍前序工作Who2com，由题可见，我们着重介绍Who2com的可学习握手机制，who2com是一项基于无人机视角的工作，其整体架构如下图所示\nWhen2com整体架构图 Communication via Three-Stage Handshake Who2come认为，整个局部区域内的所有智能体均进行通信是低效的，消耗了大量的通信资源却获得了大量相同的信息。因此，作者认为整个协作过程需要分为三步：Request, Match, Connect。其大致架构可由下图所示\n三阶段通信示意图 首先，需要协同的智能体向周围广播发出一个数据量很低的Request信息，接收到的节点将计算一个他们的键值之间的匹配度分值。此时，邻居智能体再将返回给发出Request信息的智能体。此时，中心agent将回传的进行排序，选出匹配度最高的n个邻居进行下一步Connect阶段的操作，传输大量的传感数据。 将三阶段过程用公式表示，可以写为： Request:\n是j号智能体的observation，是超参数，是生成网络。 Match:\n代表两个向量的匹配函数，、是key的生成函数， 是可学习的参数。 Connect:\n是普通智能体的local observation，是智能体的的observation。是concatenation操作。\nAirSim-CP Dataset 本文提出了适用于协同感知领域的AirSim-CP数据集，该数据集建立在AirSim模拟器[6]之上，其中一组 5架无人机飞越具有不同景观的地图，例如道路、草原、建筑物、湖泊等。目前，在AirSim-CP数据集中， 我们使用语义分割作为下游任务来对协作感知问题的方法进行基准测试。 对于每架无人机，都会记录 RGB 图像、深度图像和姿势。数据集还提供了其中一个智能体的语义分割mask。\nWhen2com: Multi-Agent Perception via Communication Graph Grouping 承接Who2com，作者进一步提出要处理协同感知领域何时进行协作的问题。在本文中，作者着重解决的是如何通过学习方法构建通信组和学习何时以带宽受限的方式进行通信。其具体示意图如下所示：\nWhen2com HandShak通信机制 作者认为以前基于学习的通信组建立的工作均应用了完全连接的通信图来跨智能体进行信息交换。该框架导致大量带宽使用，并且当智能体数量增加时难以扩展。\n完全通信图和不完全通信图 为了降低网络复杂性和带宽使用，受通信网络协议的启发，作者提出了一个两步通信组构建过程：首先应用握手通信来确定连接的权重，然后进一步修剪权重较小的边。与who2com相似，handshake过程包括Request和Match来确定连接的权重，并通过激活函数来移除部分权重较低的连接。 但是，上述方法没有学习“何时”进行通信，并且当智能体有足够的信息并且没有必要进行通信时上述机制仍然会通信，进而导致带宽浪费。理想的通信机制是当智能体需要来自其他智能体的信息以提高其感知能力时进行传输，而当它有足够的信息来完成自己的感知任务时也应该停止请求传输。为此，作者自我注意机制 的启发，使用key和来自同一代理的query之间的相关性来确定代理是否可能需要更多信息，从而了解何时进行通信：\n当时，意味着该智能体不需要额外的通信来提升感知任务的精度。为了最大限度地减少传输过程中的带宽使用，when2com进一步提出了一种非对称消息方法，将query压缩成一个极低维的向量（被传输），同时保持更大的key向量（不传输）。 一旦将极其紧凑的query传递给接收者，使用缩放的一般注意力 [7] 来计算智能体i和智能体j之间的相关性：\n是一个可学习的参数矩阵，用来匹配query和key的尺寸。于是对于一个场景而言，我们可以获得匹配矩阵:\n是一个逐行的softmax函数。再对其进行稀疏化处理，我们可以得到。\n完全通信图和不完全通信图 如when2com整体示意图所示，一旦发出请求的智能体从其链接的支持智能体收集信息，发出请求的智能体i就会根据匹配分数整合其local observation和来自支持智能体的压缩视觉特征图：\n简而言之，在Who2com的基础上乘上权值。\n我的评价是： 按照时间顺序，Who2come公布于2020年3月，When2com公布于2020年5月，V2VNet公布于2020年8月。Who2come, When2come两项工作均基于无人机视角，V2VNet基于SDV车联通信。 V2VNet为该问题搭出了一个较为全面合理的基础框架，包含了协同感知任务中的诸多模块，并设计了一些基本直观的结构来解决这些问题。但V2VNet的组成模块大多采用了比较直接基本的方法（基本的message passing GNN，经典的变分图像压缩方法，简单卷积层延迟补偿...），缺乏对V2V协同感知场景的特别设计，对于V2V的实际部署来说，还有很多问题值得思考和补充。Who2come和when2com在无人机视角下，针对于如何平衡通信带宽占用和协作感知性能，借鉴了不少通信网络的设计方法，提出了3次握手机制来解决协作的who和when的问题，是很有创意的想法，也符合通信网络系统搭建的直觉和经验。但在一些结构设计上，例如weight的设计上，我认为仍有可改进之处，在[8]中，使用pointwise weight使得协作性能得到进一步的提高。对于这三个工作，我认为他们共同的不足之处包括：将通信环境设想的过于完美和鲁棒，缺乏对通信拒止条件下的实验和分析，将大大限制协作方法的应用。此外，对于spatial information的保留和利用不够充分。在后续的工作，例如[8]中，这一系列问题部分得 …","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1567641600,"objectID":"d25b795819ef6bcc3869db5901adb309","permalink":"https://example.com/post/collaborativeperception/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/post/collaborativeperception/","section":"post","summary":"2020年-2022年的协作感知进展","tags":[],"title":"协同感知的策略设计","type":"post"},{"authors":null,"categories":null,"content":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\n","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"e8f8d235e8e7f2efd912bfe865363fc3","permalink":"https://example.com/project/example/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project/example/","section":"project","summary":"An example of using the in-built project page.","tags":["Deep Learning"],"title":"Example Project","type":"project"},{"authors":null,"categories":null,"content":"","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"d1311ddf745551c9e117aa4bb7e28516","permalink":"https://example.com/project/external-project/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project/external-project/","section":"project","summary":"An example of linking directly to an external project website using `external_link`.","tags":["Demo"],"title":"External Project","type":"project"},{"authors":["Zixing Lei","Shunli Ren","Yue Hu","Wenjun Zhang","Siheng Chen"],"categories":null,"content":" ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"6be8df78c7d97ddcbb50005908c45093","permalink":"https://example.com/publication/conference-paper/syncnet/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/publication/conference-paper/syncnet/","section":"publication","summary":"We present the first latency-aware collaborative perception system, which actively adapts asynchronous perceptual features from multiple agents to the same time stamp","tags":[],"title":"[ECCV2022] Latency-Aware Collaborative Perception","type":"publication"},{"authors":null,"categories":null,"content":"SPVNAS: 基于点云-网格的稀疏卷积的3D神经网络结构搜索 论文信息 Paper: [ECCV-2020] Searching Ecient 3D Architectures with Sparse Point-Voxel Convolution [1] Link: https://arxiv.org/pdf/2007.16100.pdf 背景梳理 为保证行驶安全性，自动驾驶汽车需要准确高效的理解3D场景。在一般场景下，激光雷达通常会扫描到数万个点，非欧地分布在整个空间中。我们可以将该过程类比于模拟图像转换为数字图像在更高的3D空间进行操作，如果按照图像离散化类似的分辨率进行网格化（例如长宽高为10^2数量级），数据量将大大增加。由于计算资源的限制，现存的3D视觉模型通常需要对点云数据进行低分辨率的网格化以及破坏性较大的下采样。对于较大物体来说，即使进行低分辨率网格化或激进的下采样，我们仍能够保留足够的信息对物体的类别进行判断，但对较小物体来说，低分辨率网格化将非常容易使其与周边物体混淆，导致模型输出错误的结果。\n为解决这一问题，2019年末，MIT Han Lab发表论文Point-Voxel CNN for Efficient 3D Deep Learning[2]，并提出新型点云处理框架 (Point-Voxel CNN，下称PVCNN)，将点云处理领域的两类思路：基于栅格和直接处理点云的方法进行了结合。PVCNN可以快速、高效地进行3D点云数据，与此同时还能避免稀疏性带来的巨大的不规则数据访存开销，提高硬件效率。PVCNN这篇文章也成为了2019年NIPS的Spotlight文章。\n虽然PVCNN在小物体和较小的区域理解中展现了强劲的性能，其在大规模室外场景上仍然无法高效部署。本文在作者之前工作的基础上，提出稀疏点云-栅格卷积（Sparse Point-Voxel Convolution ，下称SPVConv）方法。在增加的计算开销可忽略不计的前提下，使模型即使在户外大型场景中也能保留足够的细节信息。\n主要贡献 作者设计了一个轻量级的3D模块SPVConv，它可以提高在小型物体上的性能，而在有限的硬件资源下，小型物体的分割是一个很有挑战性的问题。 作者设计了第一个3D场景理解中的AutoML框架：3D-NAS，可以给出在一定约束条件下的最佳3D模型。 截止在这篇文章截稿时，该方法在Semantic KITTI数据集的点云语义分割竞赛排行榜上排名第一（目前仍排名前四）。 方法 SPV-Conv 作者分析了Point-Voxel Convolution[2]以及Sparse Convolution[3]两种方法的瓶颈，并认为这两种方法都给模型带来了非常严重的信息损失。为克服这两个模型存在的缺点，作者提出了如下图所示的SPVCNN方法。 SPVCNN由[2]中栅格表示 (Volumetric Representation) 下聚合邻域信息的思路，转而在稀疏张量 (Sparse Tensor) 表示下利用三维稀疏卷积 (3D Sparse Convolution) 来处理邻域信息。而在基于点的分支中，作者直接在每个点上应用MLP来提取各个点的特征。然后将两个分支的输出与加法进行融合，以组合所提供的完整信息。与普通稀疏卷积相比，MLP层只需花费很少的计算开销（就mac而言为4%），但在信息流中引入了重要的细节。基于点的分支通过学习，主要用在小物体分割检测中。图中标红的点是该分支中最大特征范数前5%的点，而这些点几乎均位于小物体上，意味着该分支为小物体保留了大量信息。 3D-NAS 作者提出的3D-NAS将网络的设计流程分为两个阶段，以支持高效地设计3D场景理解网络。 在第一阶段中，作者的目的是训练一个包含其设计搜索空间（Design Space）中所有可能出现的子网络的一个超大网络模型。由于该超大规模网络数量可能过于巨大，因此尽可能降低计算复杂度。首先作者提出使用分布均匀采样（Distributed Uniform Sampling）和权值共享（Weight Sharing）方法来降低搜索空间规模。以上两个方法解决了网络搜索空间的可变通道数问题。除此之外，作者还需解决另一个更具挑战性的问题：可变网络深度支持。解决这一问题的方法是：深度渐进收缩（Progressive Depth Shrinkage）策略：作者将网络的训练过程进行分段，而对每一段网络的训练过程中，作者都允许一个范围来进行网络深度的选择。这种算法用可接受的复杂度支持了任意深度的子网络。 接下来是第二阶段的任务中作者借鉴了经典的遗传算法的思路（Evolutionary Search）：在该过程中，作者将起始待选网络数量设计为n，每次迭代中作者选取表现最好的k个网络。下一次迭代的n个待选网络将由1/2的crossover和1/2的mutation组成。对于mutation操作，我们从topk待选网络中随机选择一个，将其结构按照一定的概率进行改变（网络深度，通道数量）。而对于crossover操作，我们从topk网络中随机选择两个进行组合得到新网络。\n实验 作者在Semantic KITTI数据集上对其方法进行了评估，与同样基于3D的方法比较，SPVNAS方法在准确率，参数量，运算速度上都要胜过截止到该文章发布时的SOTA方法。（下图红色数字表示计算时间，蓝色数字表示该方法特有的预处理计算时间） 与一些通过2D投影的方法相比，SPVNAS也具有较大优势。（其中红字表示网络运算时间，蓝字表示投影所需要的时间） 与当时SOTA的MinkowskiNet方法相比，作者的方法对于小物体的分割具有很大的优势。两种方法在行人，自行车，自行车手，摩托车以及摩托车手的gap要远大于其平均gap，证明了SPVConv方法对于小物体和细节物体的特殊处理起到了作用而并非只是3D-NAS对模型进行了充分fine-tuned使得结果得到提升。 MinkowskiNet对小物体及其边界的识别不及SPVNAS： 总结 本文提出了一种新型的3D点云分割方法SPVNAS，包含稀疏点云-栅格卷积以及3D-NAS两个主要部分。SPVconv通过结合基于网格的方法和基于Raw点的方法，有效保留了较小物体的信息，很大程度提升了较小物体的识别准确程度。除此之外，通过提出高效的3D-NAS AutoML结构，利用遗传算法思想，对该3D模型进行了充分的训练，使其在准确度，参数量，运算时间上都对当时的SOTA方法实现了超越。并在当时占据了Semantic KITTI数据集排行榜的第一名。\n参考文献 [1]: Tang, H., Liu, Z., Zhao, S., Lin, Y., Lin, J., Wang, H., \u0026amp; Han, S. (2020, August). Searching efficient 3d architectures with sparse point-voxel convolution. In ECCV(2020)\n[2]: Liu, Z., Tang, H., Lin, Y., Han, S.: Point-Voxel CNN for Ecient 3D Deep Learning. In: NeurIPS (2019)\n[3]: Choy, C., Gwak, J., Savarese, S.: 4D Spatio-Temporal ConvNets: Minkowski Convolutional Neural Networks. In: CVPR (2019)\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"f9bbeceff3f1de4975607e2eb785b702","permalink":"https://example.com/post/spvnas/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/post/spvnas/","section":"post","summary":"Searching Ecient 3D Architectures with Sparse Point-Voxel Convolution","tags":["PointCloud","3D","Segementation"],"title":"SPVNAS","type":"post"}]